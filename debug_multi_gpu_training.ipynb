{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a952c0af",
   "metadata": {},
   "source": [
    "# ğŸ”§ å¤šGPUè®­ç»ƒé—®é¢˜è¯Šæ–­ä¸è§£å†³\n",
    "\n",
    "**é—®é¢˜æè¿°**: åœ¨è¿è¡Œå¤šGPUè®­ç»ƒæ—¶é‡åˆ°\"Terminated\"é”™è¯¯ï¼Œè®­ç»ƒè¿›ç¨‹è¢«æ„å¤–ç»ˆæ­¢ã€‚\n",
    "\n",
    "**å¯èƒ½åŸå› åˆ†æ**:\n",
    "1. **ç«¯å£å†²çª**: å¤šä¸ªè¿›ç¨‹å°è¯•ä½¿ç”¨åŒä¸€ç«¯å£\n",
    "2. **NCCLé€šä¿¡é—®é¢˜**: GPUé—´é€šä¿¡é…ç½®é”™è¯¯\n",
    "3. **è¿›ç¨‹æ¸…ç†è¿‡åº¦**: æ¸…ç†è„šæœ¬è¯¯æ€äº†æ­£åœ¨å¯åŠ¨çš„è¿›ç¨‹\n",
    "4. **æ˜¾å­˜ä¸è¶³**: GPUæ˜¾å­˜ä¸å¤Ÿå¯¼è‡´è¿›ç¨‹å´©æºƒ\n",
    "5. **ç¯å¢ƒé…ç½®é—®é¢˜**: CUDA/NCCLç¯å¢ƒå˜é‡è®¾ç½®ä¸å½“\n",
    "\n",
    "æœ¬notebookå°†ç³»ç»Ÿæ€§åœ°è¯Šæ–­å’Œè§£å†³è¿™äº›é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f65e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å¯¼å…¥å¿…è¦çš„è°ƒè¯•åº“\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import os\n",
    "import subprocess\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "import psutil\n",
    "import signal\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"Pythonç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. æ£€æŸ¥GPUå¯ç”¨æ€§å’ŒçŠ¶æ€\n",
    "print(\"=== GPUç¯å¢ƒæ£€æŸ¥ ===\")\n",
    "\n",
    "# åŸºæœ¬CUDAæ£€æŸ¥\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDAç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "    print(f\"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"GPUæ•°é‡: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # è¯¦ç»†GPUä¿¡æ¯\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"\\nGPU {i}: {props.name}\")\n",
    "        print(f\"  æ€»æ˜¾å­˜: {props.total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"  è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}\")\n",
    "        \n",
    "        # å°è¯•è·å–æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "        try:\n",
    "            torch.cuda.set_device(i)\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            print(f\"  å·²åˆ†é…æ˜¾å­˜: {allocated:.1f} GB\")\n",
    "            print(f\"  å·²ä¿ç•™æ˜¾å­˜: {reserved:.1f} GB\")\n",
    "        except Exception as e:\n",
    "            print(f\"  æ˜¾å­˜ä¿¡æ¯è·å–å¤±è´¥: {e}\")\n",
    "else:\n",
    "    print(\"âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒGPUè®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. éªŒè¯NCCLåç«¯é…ç½®\n",
    "print(\"\\n=== NCCLåç«¯æ£€æŸ¥ ===\")\n",
    "\n",
    "# æ£€æŸ¥NCCLå¯ç”¨æ€§\n",
    "try:\n",
    "    nccl_available = torch.distributed.is_nccl_available()\n",
    "    print(f\"NCCLåç«¯å¯ç”¨: {nccl_available}\")\n",
    "    \n",
    "    if nccl_available:\n",
    "        # æ£€æŸ¥NCCLç‰ˆæœ¬\n",
    "        try:\n",
    "            import subprocess\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader,nounits'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                driver_version = result.stdout.strip().split('\\n')[0]\n",
    "                print(f\"NVIDIAé©±åŠ¨ç‰ˆæœ¬: {driver_version}\")\n",
    "        except Exception as e:\n",
    "            print(f\"é©±åŠ¨ç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}\")\n",
    "        \n",
    "        # æ£€æŸ¥é‡è¦çš„NCCLç¯å¢ƒå˜é‡\n",
    "        nccl_vars = ['NCCL_DEBUG', 'NCCL_TIMEOUT', 'NCCL_IB_DISABLE', 'NCCL_P2P_DISABLE']\n",
    "        print(\"\\nå½“å‰NCCLç¯å¢ƒå˜é‡:\")\n",
    "        for var in nccl_vars:\n",
    "            value = os.environ.get(var, 'æœªè®¾ç½®')\n",
    "            print(f\"  {var}: {value}\")\n",
    "    else:\n",
    "        print(\"âŒ NCCLåç«¯ä¸å¯ç”¨\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"NCCLæ£€æŸ¥å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. æµ‹è¯•åˆ†å¸ƒå¼è®¾ç½®å’Œç«¯å£å¯ç”¨æ€§\n",
    "print(\"\\n=== åˆ†å¸ƒå¼è®¾ç½®æµ‹è¯• ===\")\n",
    "\n",
    "def find_free_port(start_port=12355, end_port=12370):\n",
    "    \"\"\"æŸ¥æ‰¾å¯ç”¨ç«¯å£\"\"\"\n",
    "    for port in range(start_port, end_port):\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                s.bind(('localhost', port))\n",
    "                return port\n",
    "        except OSError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# æŸ¥æ‰¾å¯ç”¨ç«¯å£\n",
    "print(\"æŸ¥æ‰¾å¯ç”¨ç«¯å£...\")\n",
    "for port in range(12355, 12370):\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            s.bind(('localhost', port))\n",
    "            print(f\"âœ… ç«¯å£ {port}: å¯ç”¨\")\n",
    "            free_port = port\n",
    "            break\n",
    "    except OSError:\n",
    "        print(f\"âŒ ç«¯å£ {port}: è¢«å ç”¨\")\n",
    "else:\n",
    "    free_port = None\n",
    "    print(\"âš ï¸  åœ¨12355-12369èŒƒå›´å†…æœªæ‰¾åˆ°å¯ç”¨ç«¯å£\")\n",
    "\n",
    "if free_port:\n",
    "    print(f\"\\næ¨èä½¿ç”¨ç«¯å£: {free_port}\")\n",
    "\n",
    "# æ£€æŸ¥ç½‘ç»œè¿æ¥\n",
    "print(\"\\næ£€æŸ¥localhostè¿æ¥...\")\n",
    "try:\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.settimeout(1)\n",
    "        result = s.connect_ex(('localhost', 22))  # å°è¯•è¿æ¥SSHç«¯å£\n",
    "        if result == 0:\n",
    "            print(\"âœ… localhostç½‘ç»œè¿æ¥æ­£å¸¸\")\n",
    "        else:\n",
    "            print(\"âš ï¸  localhostè¿æ¥å¯èƒ½æœ‰é—®é¢˜\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  ç½‘ç»œæ£€æŸ¥å¼‚å¸¸: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. è°ƒè¯•CUDAè¿›ç¨‹å’Œèµ„æºå ç”¨\n",
    "print(\"\\n=== CUDAè¿›ç¨‹æ£€æŸ¥ ===\")\n",
    "\n",
    "def check_cuda_processes():\n",
    "    \"\"\"æ£€æŸ¥CUDAç›¸å…³è¿›ç¨‹\"\"\"\n",
    "    try:\n",
    "        # ä½¿ç”¨nvidia-smiæ£€æŸ¥GPUè¿›ç¨‹\n",
    "        result = subprocess.run(['nvidia-smi', 'pmon', '-c', '1'], \n",
    "                              capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            print(\"å½“å‰GPUè¿›ç¨‹:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"nvidia-smiæ£€æŸ¥å¤±è´¥\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"nvidia-smiå‘½ä»¤è¶…æ—¶\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPUè¿›ç¨‹æ£€æŸ¥å¤±è´¥: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # æ£€æŸ¥Pythonè®­ç»ƒè¿›ç¨‹\n",
    "        result = subprocess.run(['ps', 'aux'], capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            python_procs = []\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if 'python' in line and any(keyword in line for keyword in ['train', 'ddp', 'main_train']):\n",
    "                    python_procs.append(line.strip())\n",
    "            \n",
    "            if python_procs:\n",
    "                print(\"\\nå‘ç°Pythonè®­ç»ƒè¿›ç¨‹:\")\n",
    "                for proc in python_procs:\n",
    "                    print(f\"  {proc}\")\n",
    "            else:\n",
    "                print(\"\\nâœ… æœªå‘ç°å†²çªçš„Pythonè®­ç»ƒè¿›ç¨‹\")\n",
    "    except Exception as e:\n",
    "        print(f\"è¿›ç¨‹æ£€æŸ¥å¤±è´¥: {e}\")\n",
    "\n",
    "check_cuda_processes()\n",
    "\n",
    "# æ£€æŸ¥core dumpæ–‡ä»¶\n",
    "print(\"\\næ£€æŸ¥core dumpæ–‡ä»¶...\")\n",
    "try:\n",
    "    import glob\n",
    "    core_files = glob.glob('/work/home/luoyinze/paligemma-VLA/paligemma-VLA/core.*')\n",
    "    if core_files:\n",
    "        print(f\"å‘ç° {len(core_files)} ä¸ªcore dumpæ–‡ä»¶:\")\n",
    "        for core_file in core_files[-3:]:  # åªæ˜¾ç¤ºæœ€è¿‘çš„3ä¸ª\n",
    "            stat = os.stat(core_file)\n",
    "            size_mb = stat.st_size / 1024 / 1024\n",
    "            mtime = datetime.fromtimestamp(stat.st_mtime)\n",
    "            print(f\"  {os.path.basename(core_file)}: {size_mb:.1f}MB, {mtime}\")\n",
    "        print(\"\\nâš ï¸  å­˜åœ¨core dumpæ–‡ä»¶è¡¨æ˜ä¹‹å‰æœ‰è¿›ç¨‹å´©æºƒ\")\n",
    "    else:\n",
    "        print(\"âœ… æœªå‘ç°core dumpæ–‡ä»¶\")\n",
    "except Exception as e:\n",
    "    print(f\"core dumpæ£€æŸ¥å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c83195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ä¿®å¤å»ºè®®å’Œå®‰å…¨çš„è®­ç»ƒå¯åŠ¨æ–¹æ³•\n",
    "print(\"\\n=== é—®é¢˜ä¿®å¤å»ºè®® ===\")\n",
    "\n",
    "# åˆ†æé—®é¢˜\n",
    "print(\"ğŸ” é—®é¢˜åˆ†æ:\")\n",
    "print(\"1. 'Terminated'é”™è¯¯é€šå¸¸æ˜¯ç”±äºè¿›ç¨‹è¢«æ„å¤–ç»ˆæ­¢\")\n",
    "print(\"2. å¯èƒ½çš„åŸå› åŒ…æ‹¬:\")\n",
    "print(\"   - è¿›ç¨‹æ¸…ç†è„šæœ¬è¿‡äºæ¿€è¿›ï¼Œè¯¯æ€äº†æ­£åœ¨å¯åŠ¨çš„è¿›ç¨‹\")\n",
    "print(\"   - ç«¯å£å†²çªå¯¼è‡´åˆå§‹åŒ–å¤±è´¥\")\n",
    "print(\"   - NCCLé€šä¿¡é…ç½®é—®é¢˜\")\n",
    "print(\"   - æ˜¾å­˜ä¸è¶³æˆ–èµ„æºç«äº‰\")\n",
    "\n",
    "print(\"\\nğŸ› ï¸  ä¿®å¤æ–¹æ¡ˆ:\")\n",
    "print(\"1. ç§»é™¤è¿›ç¨‹æ¸…ç†ä»£ç ä¸­çš„è¿‡åº¦æ¸…ç†\")\n",
    "print(\"2. æ”¹è¿›ç«¯å£æ£€æµ‹å’Œåˆ†é…æœºåˆ¶\")\n",
    "print(\"3. æ·»åŠ æ›´å¥½çš„é”™è¯¯å¤„ç†å’ŒåŒæ­¥\")\n",
    "print(\"4. ä½¿ç”¨æ›´å®‰å…¨çš„å¯åŠ¨æ–¹å¼\")\n",
    "\n",
    "# æä¾›ä¿®å¤åçš„å¯åŠ¨å‘½ä»¤\n",
    "print(\"\\nğŸš€ å»ºè®®çš„å®‰å…¨å¯åŠ¨æ–¹å¼:\")\n",
    "print(\"\")\n",
    "print(\"æ–¹æ¡ˆ1: ä½¿ç”¨ä¿®å¤åçš„è„šæœ¬ (æ¨è)\")\n",
    "print(\"python main_train_ddp.py \\\\\")\n",
    "print(\"    --config_path configs/vla_config_ddp.yaml \\\\\")\n",
    "print(\"    --experiment_name test_fixed \\\\\")\n",
    "print(\"    --batch_size 32 \\\\\")\n",
    "print(\"    --epochs 2\")\n",
    "print(\"\")\n",
    "print(\"æ–¹æ¡ˆ2: ä½¿ç”¨ç¯å¢ƒå˜é‡æ§åˆ¶\")\n",
    "print(\"NCCL_DEBUG=WARN NCCL_TIMEOUT=1800 \\\\\")\n",
    "print(\"python main_train_ddp.py \\\\\")\n",
    "print(\"    --config_path configs/vla_config_ddp.yaml \\\\\")\n",
    "print(\"    --experiment_name test_env \\\\\")\n",
    "print(\"    --batch_size 16 \\\\\")\n",
    "print(\"    --epochs 1\")\n",
    "print(\"\")\n",
    "print(\"æ–¹æ¡ˆ3: å…ˆæµ‹è¯•2ä¸ªGPU\")\n",
    "print(\"CUDA_VISIBLE_DEVICES=0,1 \\\\\")\n",
    "print(\"python main_train_ddp.py \\\\\")\n",
    "print(\"    --config_path configs/vla_config_ddp.yaml \\\\\")\n",
    "print(\"    --experiment_name test_2gpu \\\\\")\n",
    "print(\"    --batch_size 16 \\\\\")\n",
    "print(\"    --epochs 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. æ‰§è¡Œå®é™…ä¿®å¤ - æ¸…ç†ç¯å¢ƒå¹¶å‡†å¤‡å®‰å…¨å¯åŠ¨\n",
    "print(\"\\n=== æ‰§è¡Œç¯å¢ƒæ¸…ç†å’Œä¿®å¤ ===\")\n",
    "\n",
    "# å®‰å…¨æ¸…ç†core dumpæ–‡ä»¶\n",
    "print(\"1. æ¸…ç†core dumpæ–‡ä»¶...\")\n",
    "try:\n",
    "    import glob\n",
    "    import os\n",
    "    core_files = glob.glob('/work/home/luoyinze/paligemma-VLA/paligemma-VLA/core.*')\n",
    "    if core_files:\n",
    "        for core_file in core_files:\n",
    "            try:\n",
    "                os.remove(core_file)\n",
    "                print(f\"   åˆ é™¤: {os.path.basename(core_file)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   åˆ é™¤å¤±è´¥ {os.path.basename(core_file)}: {e}\")\n",
    "        print(f\"âœ… æ¸…ç†äº† {len(core_files)} ä¸ªcore dumpæ–‡ä»¶\")\n",
    "    else:\n",
    "        print(\"âœ… æ— éœ€æ¸…ç†core dumpæ–‡ä»¶\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  core dumpæ¸…ç†å¤±è´¥: {e}\")\n",
    "\n",
    "# è®¾ç½®å®‰å…¨çš„NCCLç¯å¢ƒå˜é‡\n",
    "print(\"\\n2. è®¾ç½®NCCLç¯å¢ƒå˜é‡...\")\n",
    "safe_nccl_env = {\n",
    "    'NCCL_DEBUG': 'WARN',\n",
    "    'NCCL_TIMEOUT': '1800',\n",
    "    'NCCL_SOCKET_TIMEOUT': '600', \n",
    "    'NCCL_IB_DISABLE': '1',\n",
    "    'NCCL_P2P_DISABLE': '1'\n",
    "}\n",
    "\n",
    "for key, value in safe_nccl_env.items():\n",
    "    os.environ[key] = value\n",
    "    print(f\"   è®¾ç½® {key} = {value}\")\n",
    "\n",
    "print(\"âœ… NCCLç¯å¢ƒå˜é‡é…ç½®å®Œæˆ\")\n",
    "\n",
    "# æ£€æŸ¥ä¿®å¤åçš„è„šæœ¬æ˜¯å¦å­˜åœ¨\n",
    "print(\"\\n3. æ£€æŸ¥è®­ç»ƒè„šæœ¬...\")\n",
    "script_path = '/work/home/luoyinze/paligemma-VLA/paligemma-VLA/main_train_ddp.py'\n",
    "if os.path.exists(script_path):\n",
    "    print(f\"âœ… æ‰¾åˆ°è®­ç»ƒè„šæœ¬: {script_path}\")\n",
    "    \n",
    "    # ç®€å•æ£€æŸ¥è„šæœ¬å†…å®¹\n",
    "    with open(script_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        if 'pkill' in content:\n",
    "            print(\"âš ï¸  è„šæœ¬ä¸­ä»åŒ…å«pkillå‘½ä»¤ï¼Œå»ºè®®ç§»é™¤\")\n",
    "        else:\n",
    "            print(\"âœ… è„šæœ¬å·²ç§»é™¤å±é™©çš„è¿›ç¨‹æ¸…ç†å‘½ä»¤\")\n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ°è®­ç»ƒè„šæœ¬: {script_path}\")\n",
    "\n",
    "print(\"\\nâœ… ç¯å¢ƒä¿®å¤å®Œæˆï¼ç°åœ¨å¯ä»¥å®‰å…¨å¯åŠ¨è®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d441d",
   "metadata": {},
   "source": [
    "## ğŸ¯ æœ€ç»ˆæµ‹è¯•å’Œå¯åŠ¨æŒ‡å—\n",
    "\n",
    "æ ¹æ®ä¸Šè¿°è¯Šæ–­ç»“æœï¼Œç°åœ¨å¯ä»¥å®‰å…¨åœ°å¯åŠ¨å¤šGPUè®­ç»ƒäº†ã€‚\n",
    "\n",
    "### æ¨èçš„å¯åŠ¨é¡ºåº:\n",
    "\n",
    "1. **é¦–å…ˆæµ‹è¯•å°è§„æ¨¡è®­ç»ƒ** (2ä¸ªGPU, å°batch size)\n",
    "2. **ç„¶åæ‰©å±•åˆ°å…¨éƒ¨GPU**\n",
    "3. **æœ€åå¢åŠ batch sizeåˆ°ç›®æ ‡å€¼**\n",
    "\n",
    "### å¦‚æœä»ç„¶é‡åˆ°é—®é¢˜:\n",
    "\n",
    "1. **æ£€æŸ¥æ˜¾å­˜**: ç¡®ä¿æ¯ä¸ªGPUæœ‰è¶³å¤Ÿæ˜¾å­˜\n",
    "2. **å‡å°‘batch size**: ä»16å¼€å§‹æµ‹è¯•\n",
    "3. **æ£€æŸ¥æ•°æ®è·¯å¾„**: ç¡®ä¿è®­ç»ƒæ•°æ®å¯è®¿é—®\n",
    "4. **æŸ¥çœ‹è¯¦ç»†æ—¥å¿—**: å¯ç”¨NCCL_DEBUG=INFOè·å–æ›´å¤šä¿¡æ¯\n",
    "\n",
    "### ç›‘æ§å‘½ä»¤:\n",
    "\n",
    "åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤ç›‘æ§è®­ç»ƒ:\n",
    "```bash\n",
    "# ç›‘æ§GPUä½¿ç”¨\n",
    "watch -n 1 nvidia-smi\n",
    "\n",
    "# ç›‘æ§è®­ç»ƒæ—¥å¿—\n",
    "tail -f experiments/test_fixed/logs/train_log_ddp_*.log\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
