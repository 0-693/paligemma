{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a952c0af",
   "metadata": {},
   "source": [
    "# 🔧 多GPU训练问题诊断与解决\n",
    "\n",
    "**问题描述**: 在运行多GPU训练时遇到\"Terminated\"错误，训练进程被意外终止。\n",
    "\n",
    "**可能原因分析**:\n",
    "1. **端口冲突**: 多个进程尝试使用同一端口\n",
    "2. **NCCL通信问题**: GPU间通信配置错误\n",
    "3. **进程清理过度**: 清理脚本误杀了正在启动的进程\n",
    "4. **显存不足**: GPU显存不够导致进程崩溃\n",
    "5. **环境配置问题**: CUDA/NCCL环境变量设置不当\n",
    "\n",
    "本notebook将系统性地诊断和解决这些问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f65e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 导入必要的调试库\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import os\n",
    "import subprocess\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "import psutil\n",
    "import signal\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"Python版本: {sys.version}\")\n",
    "print(f\"当前时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 检查GPU可用性和状态\n",
    "print(\"=== GPU环境检查 ===\")\n",
    "\n",
    "# 基本CUDA检查\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA版本: {torch.version.cuda}\")\n",
    "    print(f\"cuDNN版本: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"GPU数量: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # 详细GPU信息\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"\\nGPU {i}: {props.name}\")\n",
    "        print(f\"  总显存: {props.total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"  计算能力: {props.major}.{props.minor}\")\n",
    "        \n",
    "        # 尝试获取显存使用情况\n",
    "        try:\n",
    "            torch.cuda.set_device(i)\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            print(f\"  已分配显存: {allocated:.1f} GB\")\n",
    "            print(f\"  已保留显存: {reserved:.1f} GB\")\n",
    "        except Exception as e:\n",
    "            print(f\"  显存信息获取失败: {e}\")\n",
    "else:\n",
    "    print(\"❌ CUDA不可用，无法进行GPU训练\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 验证NCCL后端配置\n",
    "print(\"\\n=== NCCL后端检查 ===\")\n",
    "\n",
    "# 检查NCCL可用性\n",
    "try:\n",
    "    nccl_available = torch.distributed.is_nccl_available()\n",
    "    print(f\"NCCL后端可用: {nccl_available}\")\n",
    "    \n",
    "    if nccl_available:\n",
    "        # 检查NCCL版本\n",
    "        try:\n",
    "            import subprocess\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader,nounits'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                driver_version = result.stdout.strip().split('\\n')[0]\n",
    "                print(f\"NVIDIA驱动版本: {driver_version}\")\n",
    "        except Exception as e:\n",
    "            print(f\"驱动版本检查失败: {e}\")\n",
    "        \n",
    "        # 检查重要的NCCL环境变量\n",
    "        nccl_vars = ['NCCL_DEBUG', 'NCCL_TIMEOUT', 'NCCL_IB_DISABLE', 'NCCL_P2P_DISABLE']\n",
    "        print(\"\\n当前NCCL环境变量:\")\n",
    "        for var in nccl_vars:\n",
    "            value = os.environ.get(var, '未设置')\n",
    "            print(f\"  {var}: {value}\")\n",
    "    else:\n",
    "        print(\"❌ NCCL后端不可用\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"NCCL检查失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 测试分布式设置和端口可用性\n",
    "print(\"\\n=== 分布式设置测试 ===\")\n",
    "\n",
    "def find_free_port(start_port=12355, end_port=12370):\n",
    "    \"\"\"查找可用端口\"\"\"\n",
    "    for port in range(start_port, end_port):\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                s.bind(('localhost', port))\n",
    "                return port\n",
    "        except OSError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# 查找可用端口\n",
    "print(\"查找可用端口...\")\n",
    "for port in range(12355, 12370):\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            s.bind(('localhost', port))\n",
    "            print(f\"✅ 端口 {port}: 可用\")\n",
    "            free_port = port\n",
    "            break\n",
    "    except OSError:\n",
    "        print(f\"❌ 端口 {port}: 被占用\")\n",
    "else:\n",
    "    free_port = None\n",
    "    print(\"⚠️  在12355-12369范围内未找到可用端口\")\n",
    "\n",
    "if free_port:\n",
    "    print(f\"\\n推荐使用端口: {free_port}\")\n",
    "\n",
    "# 检查网络连接\n",
    "print(\"\\n检查localhost连接...\")\n",
    "try:\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.settimeout(1)\n",
    "        result = s.connect_ex(('localhost', 22))  # 尝试连接SSH端口\n",
    "        if result == 0:\n",
    "            print(\"✅ localhost网络连接正常\")\n",
    "        else:\n",
    "            print(\"⚠️  localhost连接可能有问题\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  网络检查异常: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 调试CUDA进程和资源占用\n",
    "print(\"\\n=== CUDA进程检查 ===\")\n",
    "\n",
    "def check_cuda_processes():\n",
    "    \"\"\"检查CUDA相关进程\"\"\"\n",
    "    try:\n",
    "        # 使用nvidia-smi检查GPU进程\n",
    "        result = subprocess.run(['nvidia-smi', 'pmon', '-c', '1'], \n",
    "                              capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            print(\"当前GPU进程:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"nvidia-smi检查失败\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"nvidia-smi命令超时\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU进程检查失败: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # 检查Python训练进程\n",
    "        result = subprocess.run(['ps', 'aux'], capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            python_procs = []\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if 'python' in line and any(keyword in line for keyword in ['train', 'ddp', 'main_train']):\n",
    "                    python_procs.append(line.strip())\n",
    "            \n",
    "            if python_procs:\n",
    "                print(\"\\n发现Python训练进程:\")\n",
    "                for proc in python_procs:\n",
    "                    print(f\"  {proc}\")\n",
    "            else:\n",
    "                print(\"\\n✅ 未发现冲突的Python训练进程\")\n",
    "    except Exception as e:\n",
    "        print(f\"进程检查失败: {e}\")\n",
    "\n",
    "check_cuda_processes()\n",
    "\n",
    "# 检查core dump文件\n",
    "print(\"\\n检查core dump文件...\")\n",
    "try:\n",
    "    import glob\n",
    "    core_files = glob.glob('/work/home/luoyinze/paligemma-VLA/paligemma-VLA/core.*')\n",
    "    if core_files:\n",
    "        print(f\"发现 {len(core_files)} 个core dump文件:\")\n",
    "        for core_file in core_files[-3:]:  # 只显示最近的3个\n",
    "            stat = os.stat(core_file)\n",
    "            size_mb = stat.st_size / 1024 / 1024\n",
    "            mtime = datetime.fromtimestamp(stat.st_mtime)\n",
    "            print(f\"  {os.path.basename(core_file)}: {size_mb:.1f}MB, {mtime}\")\n",
    "        print(\"\\n⚠️  存在core dump文件表明之前有进程崩溃\")\n",
    "    else:\n",
    "        print(\"✅ 未发现core dump文件\")\n",
    "except Exception as e:\n",
    "    print(f\"core dump检查失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c83195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 修复建议和安全的训练启动方法\n",
    "print(\"\\n=== 问题修复建议 ===\")\n",
    "\n",
    "# 分析问题\n",
    "print(\"🔍 问题分析:\")\n",
    "print(\"1. 'Terminated'错误通常是由于进程被意外终止\")\n",
    "print(\"2. 可能的原因包括:\")\n",
    "print(\"   - 进程清理脚本过于激进，误杀了正在启动的进程\")\n",
    "print(\"   - 端口冲突导致初始化失败\")\n",
    "print(\"   - NCCL通信配置问题\")\n",
    "print(\"   - 显存不足或资源竞争\")\n",
    "\n",
    "print(\"\\n🛠️  修复方案:\")\n",
    "print(\"1. 移除进程清理代码中的过度清理\")\n",
    "print(\"2. 改进端口检测和分配机制\")\n",
    "print(\"3. 添加更好的错误处理和同步\")\n",
    "print(\"4. 使用更安全的启动方式\")\n",
    "\n",
    "# 提供修复后的启动命令\n",
    "print(\"\\n🚀 建议的安全启动方式:\")\n",
    "print(\"\")\n",
    "print(\"方案1: 使用修复后的脚本 (推荐)\")\n",
    "print(\"python main_train_ddp.py \\\\\")\n",
    "print(\"    --config_path configs/vla_config_ddp.yaml \\\\\")\n",
    "print(\"    --experiment_name test_fixed \\\\\")\n",
    "print(\"    --batch_size 32 \\\\\")\n",
    "print(\"    --epochs 2\")\n",
    "print(\"\")\n",
    "print(\"方案2: 使用环境变量控制\")\n",
    "print(\"NCCL_DEBUG=WARN NCCL_TIMEOUT=1800 \\\\\")\n",
    "print(\"python main_train_ddp.py \\\\\")\n",
    "print(\"    --config_path configs/vla_config_ddp.yaml \\\\\")\n",
    "print(\"    --experiment_name test_env \\\\\")\n",
    "print(\"    --batch_size 16 \\\\\")\n",
    "print(\"    --epochs 1\")\n",
    "print(\"\")\n",
    "print(\"方案3: 先测试2个GPU\")\n",
    "print(\"CUDA_VISIBLE_DEVICES=0,1 \\\\\")\n",
    "print(\"python main_train_ddp.py \\\\\")\n",
    "print(\"    --config_path configs/vla_config_ddp.yaml \\\\\")\n",
    "print(\"    --experiment_name test_2gpu \\\\\")\n",
    "print(\"    --batch_size 16 \\\\\")\n",
    "print(\"    --epochs 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 执行实际修复 - 清理环境并准备安全启动\n",
    "print(\"\\n=== 执行环境清理和修复 ===\")\n",
    "\n",
    "# 安全清理core dump文件\n",
    "print(\"1. 清理core dump文件...\")\n",
    "try:\n",
    "    import glob\n",
    "    import os\n",
    "    core_files = glob.glob('/work/home/luoyinze/paligemma-VLA/paligemma-VLA/core.*')\n",
    "    if core_files:\n",
    "        for core_file in core_files:\n",
    "            try:\n",
    "                os.remove(core_file)\n",
    "                print(f\"   删除: {os.path.basename(core_file)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   删除失败 {os.path.basename(core_file)}: {e}\")\n",
    "        print(f\"✅ 清理了 {len(core_files)} 个core dump文件\")\n",
    "    else:\n",
    "        print(\"✅ 无需清理core dump文件\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  core dump清理失败: {e}\")\n",
    "\n",
    "# 设置安全的NCCL环境变量\n",
    "print(\"\\n2. 设置NCCL环境变量...\")\n",
    "safe_nccl_env = {\n",
    "    'NCCL_DEBUG': 'WARN',\n",
    "    'NCCL_TIMEOUT': '1800',\n",
    "    'NCCL_SOCKET_TIMEOUT': '600', \n",
    "    'NCCL_IB_DISABLE': '1',\n",
    "    'NCCL_P2P_DISABLE': '1'\n",
    "}\n",
    "\n",
    "for key, value in safe_nccl_env.items():\n",
    "    os.environ[key] = value\n",
    "    print(f\"   设置 {key} = {value}\")\n",
    "\n",
    "print(\"✅ NCCL环境变量配置完成\")\n",
    "\n",
    "# 检查修复后的脚本是否存在\n",
    "print(\"\\n3. 检查训练脚本...\")\n",
    "script_path = '/work/home/luoyinze/paligemma-VLA/paligemma-VLA/main_train_ddp.py'\n",
    "if os.path.exists(script_path):\n",
    "    print(f\"✅ 找到训练脚本: {script_path}\")\n",
    "    \n",
    "    # 简单检查脚本内容\n",
    "    with open(script_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        if 'pkill' in content:\n",
    "            print(\"⚠️  脚本中仍包含pkill命令，建议移除\")\n",
    "        else:\n",
    "            print(\"✅ 脚本已移除危险的进程清理命令\")\n",
    "else:\n",
    "    print(f\"❌ 未找到训练脚本: {script_path}\")\n",
    "\n",
    "print(\"\\n✅ 环境修复完成！现在可以安全启动训练\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d441d",
   "metadata": {},
   "source": [
    "## 🎯 最终测试和启动指南\n",
    "\n",
    "根据上述诊断结果，现在可以安全地启动多GPU训练了。\n",
    "\n",
    "### 推荐的启动顺序:\n",
    "\n",
    "1. **首先测试小规模训练** (2个GPU, 小batch size)\n",
    "2. **然后扩展到全部GPU**\n",
    "3. **最后增加batch size到目标值**\n",
    "\n",
    "### 如果仍然遇到问题:\n",
    "\n",
    "1. **检查显存**: 确保每个GPU有足够显存\n",
    "2. **减少batch size**: 从16开始测试\n",
    "3. **检查数据路径**: 确保训练数据可访问\n",
    "4. **查看详细日志**: 启用NCCL_DEBUG=INFO获取更多信息\n",
    "\n",
    "### 监控命令:\n",
    "\n",
    "在另一个终端运行以下命令监控训练:\n",
    "```bash\n",
    "# 监控GPU使用\n",
    "watch -n 1 nvidia-smi\n",
    "\n",
    "# 监控训练日志\n",
    "tail -f experiments/test_fixed/logs/train_log_ddp_*.log\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
